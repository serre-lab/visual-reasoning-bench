# Example configuration for running an OpenRouter VLM on the VPT benchmark

dataset:
  name: vpt
  data_dir: "."
  params:
    hf_dataset: "3D-PC/3D-PC"
    hf_config: "depth"         # depth | vpt-basic | vpt-strategy
    split: "validation"        # train | validation | test | human
    hf_cache_dir: null         # optional override
    limit: 25                   # set to an int for smoke tests
    positive_answer: "yes"
    negative_answer: "no"
    shuffle_samples: true

models:
  - name: openrouter
    params:
      model_slug: "openai/gpt-4o"
      temperature: 0.0
      max_output_tokens: 1000
      force_binary: true
  - name: openrouter
    params:
      model_slug: "google/gemini-3-pro-preview"
      temperature: 0.0
      max_output_tokens: 4000
      force_binary: true
  - name: openrouter
    params:
      model_slug: "openai/gpt-5.1"
      temperature: 0.0
      max_output_tokens: 1000
      force_binary: true
  - name: openrouter
    params:
      model_slug: "openai/gpt-4o-2024-11-20"
      temperature: 0.0
      max_output_tokens: 500
      force_binary: true
  - name: openrouter
    params:
      model_slug: "anthropic/claude-opus-4.5"
      temperature: 0.0
      max_output_tokens: 500
      force_binary: true

evaluation:
  batch_size: 1
  num_workers: 1
  verbose: true

output:
  results_dir: ./results
  save_predictions: true
  save_visualizations: false
