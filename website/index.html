<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Visual Reasoning Bench - VLM Benchmarking Pipeline</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            border-radius: 12px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            overflow: hidden;
        }
        
        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }
        
        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }
        
        header p {
            font-size: 1.2em;
            opacity: 0.95;
        }
        
        .content {
            padding: 40px;
        }
        
        h2 {
            color: #667eea;
            margin: 30px 0 15px 0;
            font-size: 1.8em;
            border-bottom: 2px solid #667eea;
            padding-bottom: 8px;
        }
        
        h3 {
            color: #764ba2;
            margin: 20px 0 10px 0;
            font-size: 1.3em;
        }
        
        p {
            margin-bottom: 15px;
        }
        
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        }
        
        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 8px;
            overflow-x: auto;
            margin: 15px 0;
        }
        
        pre code {
            background: none;
            padding: 0;
            color: #f8f8f2;
        }
        
        .features {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 20px;
            margin: 30px 0;
        }
        
        .feature {
            background: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            border-left: 4px solid #667eea;
        }
        
        .feature h3 {
            margin-top: 0;
            color: #667eea;
        }
        
        ul {
            margin-left: 20px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        footer {
            background: #2d2d2d;
            color: white;
            text-align: center;
            padding: 20px;
            font-size: 0.9em;
        }
        
        footer a {
            color: #667eea;
            text-decoration: none;
        }
        
        footer a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ğŸ” Visual Reasoning Bench</h1>
            <p>A Minimal Python Pipeline for VLM Benchmarking</p>
        </header>
        
        <div class="content">
            <section>
                <h2>About</h2>
                <p>
                    Visual Reasoning Bench is a lightweight, modular Python framework for evaluating 
                    Vision-Language Models (VLMs) on visual reasoning tasks. It provides a clean 
                    architecture for datasets, models, and evaluation metrics.
                </p>
            </section>
            
            <section>
                <h2>Features</h2>
                <div class="features">
                    <div class="feature">
                        <h3>ğŸ“Š Datasets</h3>
                        <p>Extensible dataset interface with built-in support for Pathfinder and easy integration of custom datasets.</p>
                    </div>
                    <div class="feature">
                        <h3>ğŸ¤– Models</h3>
                        <p>Modular model interface supporting LLaVA and other VLMs with simple predict API.</p>
                    </div>
                    <div class="feature">
                        <h3>ğŸ“ˆ Evaluation</h3>
                        <p>Comprehensive evaluation pipeline with accuracy metrics and detailed result tracking.</p>
                    </div>
                </div>
            </section>
            
            <section>
                <h2>Quick Start</h2>
                
                <h3>Installation</h3>
                <pre><code>git clone https://github.com/serre-lab/visual-reasoning-bench.git
cd visual-reasoning-bench
pip install -r requirements.txt  # (when available)</code></pre>
                
                <h3>Run Evaluation</h3>
                <pre><code>python scripts/run_eval.py --config configs/example.yaml --verbose</code></pre>
                
                <h3>Project Structure</h3>
                <pre><code>visual-reasoning-bench/
â”œâ”€â”€ bench/
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ base.py          # Base dataset class
â”‚   â”‚   â””â”€â”€ pathfinder.py    # Pathfinder dataset
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ base.py          # Base model class
â”‚   â”‚   â””â”€â”€ llava.py         # LLaVA model wrapper
â”‚   â”œâ”€â”€ evaluate/
â”‚   â”‚   â”œâ”€â”€ evaluator.py     # Evaluation pipeline
â”‚   â”‚   â””â”€â”€ metrics.py       # Metrics computation
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ io.py            # I/O utilities
â”‚       â””â”€â”€ images.py        # Image utilities
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ run_eval.py          # Main evaluation script
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ example.yaml         # Example configuration
â””â”€â”€ website/
    â””â”€â”€ index.html           # This page</code></pre>
            </section>
            
            <section>
                <h2>Architecture</h2>
                <ul>
                    <li><strong>Dataset:</strong> Yields samples with <code>{id, image_path, question, answer}</code></li>
                    <li><strong>Model:</strong> Implements <code>predict(image_path, question) â†’ str</code></li>
                    <li><strong>Evaluator:</strong> Runs model on dataset and computes accuracy metrics</li>
                </ul>
            </section>
            
            <section>
                <h2>Extending the Framework</h2>
                
                <h3>Add a New Dataset</h3>
                <pre><code>from bench.datasets import BaseDataset

class MyDataset(BaseDataset):
    def _load_data(self):
        # Load your data here
        self.samples = [...]</code></pre>
                
                <h3>Add a New Model</h3>
                <pre><code>from bench.models import BaseModel

class MyModel(BaseModel):
    def predict(self, image_path, question):
        # Your inference code here
        return prediction</code></pre>
            </section>
        </div>
        
        <footer>
            <p>Visual Reasoning Bench | <a href="https://github.com/serre-lab/visual-reasoning-bench">GitHub</a></p>
        </footer>
    </div>
</body>
</html>
